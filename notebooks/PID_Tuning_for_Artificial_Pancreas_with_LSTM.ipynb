{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook implements a data-driven approach for tuning PID controller parameters (Kp, Ki, Kd) using an LSTM neural network for artificial pancreas systems in Type-1 Diabetes care. The workflow includes parsing CGM data from XML, extracting time-series features, training an LSTM model to predict PID gains based on glucose dynamics, and validating the model on real patient data. The final model is saved and can be integrated into a closed-loop insulin delivery system for personalized glucose regulation."
      ],
      "metadata": {
        "id": "F0GY7ewgcgw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Import Libraries"
      ],
      "metadata": {
        "id": "LsDWtVfKTVKh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime"
      ],
      "outputs": [],
      "metadata": {
        "id": "jdz6LPVdTUwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Validate XML Data"
      ],
      "metadata": {
        "id": "w9iRglWATZbs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Automatically loads all XML files from the dataset directory\n",
        "# Filters: training files end with '-ws-training.xml', testing with '-ws-testing.xml'\n",
        "train_files = sorted(glob.glob(\"data/test/*-ws-training.xml\"))\n",
        "test_files = sorted(glob.glob(\"data/train/*-ws-testing.xml\"))\n",
        "\n",
        "\"\"\"Check Corrupted XML Files\"\"\"\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Iterate through all training and testing XML files\n",
        "# Attempt to parse each file to ensure it is not corrupted\n",
        "for file in train_files + test_files:\n",
        "    try:\n",
        "        tree = ET.parse(file)\n",
        "        print(f\"✅ {file} is valid\")\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"❌ Error in {file}: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ /content/drive/MyDrive/GP PID/dataset/559-ws-training.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/563-ws-training.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/570-ws-training.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/575-ws-training.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/588-ws-training.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/591-ws-training.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/559-ws-testing.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/563-ws-testing.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/570-ws-testing.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/575-ws-testing.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/588-ws-testing.xml is valid\n",
            "✅ /content/drive/MyDrive/GP PID/dataset/591-ws-testing.xml is valid\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYyKdpEUTjHV",
        "outputId": "86d86d60-1703-4c5c-f2d4-c05a255b31d6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse XML to DataFrames"
      ],
      "metadata": {
        "id": "WKfMfIn3TrWi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Parses XML file and extracts timestamped glucose readings with patient weight\n",
        "def parse_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "    data = []\n",
        "\n",
        "     # Extract patient weight from root attributes (default to 0 if not present)\n",
        "    weight = float(root.get('weight', 0))\n",
        "\n",
        "    # Extract timestamp and glucose value from each glucose_level entry\n",
        "    for event in root.find('glucose_level'):\n",
        "        timestamp = datetime.strptime(event.get('ts'), \"%d-%m-%Y %H:%M:%S\")\n",
        "        glucose = float(event.get('value'))\n",
        "\n",
        "\n",
        "        # Append extracted data\n",
        "        data.append({\n",
        "            'timestamp': timestamp,\n",
        "            'glucose': glucose,\n",
        "            'weight': weight\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Display parsing result for validation\n",
        "    print(f\"Parsed {file_path}, {len(df)} records\")\n",
        "    print(df.head(10))  # View first 10 rows\n",
        "\n",
        "    # Return DataFrame sorted by timestamp to maintain chronological order\n",
        "    return df.sort_values('timestamp')\n",
        "\n",
        "# Parse and combine all training and testing data into single DataFrames\n",
        "train_df = pd.concat([parse_xml(f) for f in train_files], ignore_index=True)\n",
        "test_df = pd.concat([parse_xml(f) for f in test_files], ignore_index=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsed /content/drive/MyDrive/GP PID/dataset/559-ws-training.xml, 10796 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-12-07 01:17:00    101.0    99.0\n",
            "1 2021-12-07 01:22:00     98.0    99.0\n",
            "2 2021-12-07 01:27:00    104.0    99.0\n",
            "3 2021-12-07 01:32:00    112.0    99.0\n",
            "4 2021-12-07 01:37:00    120.0    99.0\n",
            "5 2021-12-07 01:42:00    127.0    99.0\n",
            "6 2021-12-07 01:47:00    135.0    99.0\n",
            "7 2021-12-07 01:52:00    142.0    99.0\n",
            "8 2021-12-07 01:57:00    140.0    99.0\n",
            "9 2021-12-07 02:02:00    145.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/563-ws-training.xml, 12124 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-09-13 12:33:00    219.0    99.0\n",
            "1 2021-09-13 12:38:00    229.0    99.0\n",
            "2 2021-09-13 12:43:00    224.0    99.0\n",
            "3 2021-09-13 12:48:00    221.0    99.0\n",
            "4 2021-09-13 12:53:00    215.0    99.0\n",
            "5 2021-09-13 12:58:00    209.0    99.0\n",
            "6 2021-09-13 13:03:00    203.0    99.0\n",
            "7 2021-09-13 13:08:00    199.0    99.0\n",
            "8 2021-09-13 13:13:00    196.0    99.0\n",
            "9 2021-09-13 13:18:00    196.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/570-ws-training.xml, 10982 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-12-07 16:29:00    101.0    99.0\n",
            "1 2021-12-07 16:34:00    100.0    99.0\n",
            "2 2021-12-07 16:39:00    100.0    99.0\n",
            "3 2021-12-07 16:44:00     99.0    99.0\n",
            "4 2021-12-07 16:49:00     98.0    99.0\n",
            "5 2021-12-07 16:54:00     98.0    99.0\n",
            "6 2021-12-07 16:59:00     95.0    99.0\n",
            "7 2021-12-07 17:04:00     94.0    99.0\n",
            "8 2021-12-07 17:09:00     92.0    99.0\n",
            "9 2021-12-07 17:14:00     90.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/575-ws-training.xml, 11866 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-11-17 12:04:00    128.0    99.0\n",
            "1 2021-11-17 12:09:00    123.0    99.0\n",
            "2 2021-11-17 12:14:00    120.0    99.0\n",
            "3 2021-11-17 12:19:00    124.0    99.0\n",
            "4 2021-11-17 12:24:00    121.0    99.0\n",
            "5 2021-11-17 12:29:00    120.0    99.0\n",
            "6 2021-11-17 12:34:00    121.0    99.0\n",
            "7 2021-11-17 12:39:00    121.0    99.0\n",
            "8 2021-11-17 12:44:00    120.0    99.0\n",
            "9 2021-11-17 12:49:00    119.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/588-ws-training.xml, 12640 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-08-30 11:53:00    116.0    99.0\n",
            "1 2021-08-30 11:58:00    117.0    99.0\n",
            "2 2021-08-30 12:03:00    119.0    99.0\n",
            "3 2021-08-30 12:08:00    116.0    99.0\n",
            "4 2021-08-30 12:13:00    111.0    99.0\n",
            "5 2021-08-30 12:18:00    110.0    99.0\n",
            "6 2021-08-30 12:23:00    111.0    99.0\n",
            "7 2021-08-30 12:28:00    113.0    99.0\n",
            "8 2021-08-30 12:33:00    114.0    99.0\n",
            "9 2021-08-30 12:38:00    117.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/591-ws-training.xml, 10847 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-11-30 17:06:00    160.0    99.0\n",
            "1 2021-11-30 17:11:00    158.0    99.0\n",
            "2 2021-11-30 17:16:00    160.0    99.0\n",
            "3 2021-11-30 17:21:00    166.0    99.0\n",
            "4 2021-11-30 17:26:00    175.0    99.0\n",
            "5 2021-11-30 17:31:00    182.0    99.0\n",
            "6 2021-11-30 17:36:00    188.0    99.0\n",
            "7 2021-11-30 17:41:00    192.0    99.0\n",
            "8 2021-11-30 17:46:00    191.0    99.0\n",
            "9 2021-11-30 17:51:00    192.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/559-ws-testing.xml, 2514 records\n",
            "            timestamp  glucose  weight\n",
            "0 2022-01-18 00:01:00    179.0    99.0\n",
            "1 2022-01-18 00:06:00    183.0    99.0\n",
            "2 2022-01-18 00:11:00    187.0    99.0\n",
            "3 2022-01-18 00:16:00    191.0    99.0\n",
            "4 2022-01-18 00:21:00    195.0    99.0\n",
            "5 2022-01-18 00:26:00    199.0    99.0\n",
            "6 2022-01-18 00:31:00    204.0    99.0\n",
            "7 2022-01-18 00:36:00    209.0    99.0\n",
            "8 2022-01-18 00:41:00    211.0    99.0\n",
            "9 2022-01-18 00:46:00    211.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/563-ws-testing.xml, 2570 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-10-29 00:01:00    239.0    99.0\n",
            "1 2021-10-29 00:06:00    238.0    99.0\n",
            "2 2021-10-29 00:11:00    235.0    99.0\n",
            "3 2021-10-29 00:16:00    233.0    99.0\n",
            "4 2021-10-29 00:21:00    231.0    99.0\n",
            "5 2021-10-29 00:26:00    229.0    99.0\n",
            "6 2021-10-29 00:31:00    227.0    99.0\n",
            "7 2021-10-29 00:36:00    222.0    99.0\n",
            "8 2021-10-29 00:41:00    220.0    99.0\n",
            "9 2021-10-29 00:46:00    216.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/570-ws-testing.xml, 2745 records\n",
            "            timestamp  glucose  weight\n",
            "0 2022-01-17 00:04:00    135.0    99.0\n",
            "1 2022-01-17 00:09:00    143.0    99.0\n",
            "2 2022-01-17 00:14:00    152.0    99.0\n",
            "3 2022-01-17 00:19:00    159.0    99.0\n",
            "4 2022-01-17 00:24:00    166.0    99.0\n",
            "5 2022-01-17 00:29:00    172.0    99.0\n",
            "6 2022-01-17 00:34:00    178.0    99.0\n",
            "7 2022-01-17 00:39:00    184.0    99.0\n",
            "8 2022-01-17 00:44:00    191.0    99.0\n",
            "9 2022-01-17 00:49:00    195.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/575-ws-testing.xml, 2590 records\n",
            "            timestamp  glucose  weight\n",
            "0 2022-01-02 00:00:00    214.0    99.0\n",
            "1 2022-01-02 00:05:00    217.0    99.0\n",
            "2 2022-01-02 00:10:00    217.0    99.0\n",
            "3 2022-01-02 00:15:00    212.0    99.0\n",
            "4 2022-01-02 00:20:00    209.0    99.0\n",
            "5 2022-01-02 00:25:00    208.0    99.0\n",
            "6 2022-01-02 00:30:00    209.0    99.0\n",
            "7 2022-01-02 00:35:00    209.0    99.0\n",
            "8 2022-01-02 00:40:00    208.0    99.0\n",
            "9 2022-01-02 00:45:00    207.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/588-ws-testing.xml, 2791 records\n",
            "            timestamp  glucose  weight\n",
            "0 2021-10-15 00:00:00    127.0    99.0\n",
            "1 2021-10-15 00:05:00    123.0    99.0\n",
            "2 2021-10-15 00:10:00    118.0    99.0\n",
            "3 2021-10-15 00:15:00    112.0    99.0\n",
            "4 2021-10-15 00:20:00    108.0    99.0\n",
            "5 2021-10-15 00:25:00    106.0    99.0\n",
            "6 2021-10-15 00:30:00    103.0    99.0\n",
            "7 2021-10-15 00:35:00     98.0    99.0\n",
            "8 2021-10-15 00:40:00     95.0    99.0\n",
            "9 2021-10-15 00:45:00     93.0    99.0\n",
            "Parsed /content/drive/MyDrive/GP PID/dataset/591-ws-testing.xml, 2760 records\n",
            "            timestamp  glucose  weight\n",
            "0 2022-01-14 00:03:00    283.0    99.0\n",
            "1 2022-01-14 00:08:00    282.0    99.0\n",
            "2 2022-01-14 00:13:00    281.0    99.0\n",
            "3 2022-01-14 00:18:00    277.0    99.0\n",
            "4 2022-01-14 00:23:00    267.0    99.0\n",
            "5 2022-01-14 00:28:00    258.0    99.0\n",
            "6 2022-01-14 00:33:00    251.0    99.0\n",
            "7 2022-01-14 00:38:00    237.0    99.0\n",
            "8 2022-01-14 00:43:00    226.0    99.0\n",
            "9 2022-01-14 00:48:00    216.0    99.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g54nrGpuTxOE",
        "outputId": "2924bd21-b5ab-43d8-ff1d-c6de2adcb208"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess Time Features (Cyclic Encoding)"
      ],
      "metadata": {
        "id": "g_HC4Mw9TyTd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Preprocess time-based features using cyclic encoding for hour of the day\n",
        "def preprocess_time_features(df):\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['minute'] = df['timestamp'].dt.minute\n",
        "\n",
        "    # Encode time as cyclic features to preserve periodicity (e.g., 23:00 ≈ 00:00)\n",
        "    df['time_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "    df['time_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "\n",
        "     # Drop raw timestamp and intermediate columns to avoid redundancy\n",
        "    return df.drop(['timestamp', 'hour', 'minute'], axis=1)\n",
        "\n",
        "# Apply preprocessing to training and testing datasets\n",
        "train_df = preprocess_time_features(train_df)\n",
        "test_df = preprocess_time_features(test_df)\n",
        "\n",
        "# Convert all numerical values to float32 to optimize memory usage and ensure consistency for model input\n",
        "train_df = train_df.astype(np.float32)\n",
        "test_df = test_df.astype(np.float32)"
      ],
      "outputs": [],
      "metadata": {
        "id": "9gSI79SRULwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare Training Data for LSTM-PID Model"
      ],
      "metadata": {
        "id": "a6ZzwgxlUbnh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Prepare training data for LSTM-based PID gain prediction\n",
        "def prepare_pid_training_data(df, sequence_length=30):\n",
        "    X_pid, y_pid = [], []\n",
        "\n",
        "    # Loop through the dataset to create sequences of input-output pairs\n",
        "    for i in range(len(df) - sequence_length):\n",
        "         # Calculate glucose error from the target (setpoint = 120 mg/dL)\n",
        "        glucose_error = df['glucose'].iloc[i] - 120\n",
        "\n",
        "         # Calculate the rate of glucose change (first derivative)\n",
        "        glucose_change = df['glucose'].iloc[i] - df['glucose'].iloc[i-1] if i > 0 else 0\n",
        "\n",
        "        # Estimate PID controller gains using log-scaled transformations\n",
        "        Kp = 0.05 * np.log(1 + abs(glucose_error))\n",
        "        Ki = 0.005 * np.log(1 + abs(glucose_error))\n",
        "        Kd = 0.002 * np.log(1 + abs(glucose_change))\n",
        "\n",
        "         # Prepare input features: error, change, weight, and encoded time features\n",
        "        X_pid.append([glucose_error, glucose_change, df['weight'].iloc[i],\n",
        "                      df['time_sin'].iloc[i], df['time_cos'].iloc[i]])\n",
        "\n",
        "         # Prepare corresponding target PID gains\n",
        "        y_pid.append([Kp, Ki, Kd])\n",
        "\n",
        "    return np.array(X_pid), np.array(y_pid)\n",
        "\n",
        "# Generate training and testing datasets for the model\n",
        "X_pid_train, y_pid_train = prepare_pid_training_data(train_df)\n",
        "X_pid_test, y_pid_test = prepare_pid_training_data(test_df)"
      ],
      "outputs": [],
      "metadata": {
        "id": "XqEII9k3UcUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and Compile LSTM Model"
      ],
      "metadata": {
        "id": "JcTWdeVDUgl0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Define the input shape for the LSTM model: (timesteps, features)\n",
        "pid_input = Input(shape=(X_pid_train.shape[1], 1))\n",
        "\n",
        "# First LSTM layer with 64 units, returning sequences to feed into next LSTM\n",
        "pid_lstm = LSTM(64, activation='tanh', return_sequences=True)(pid_input)\n",
        "\n",
        "# Second LSTM layer with 32 units, outputting the final sequence representation\n",
        "pid_lstm = LSTM(32, activation='tanh')(pid_lstm)\n",
        "\n",
        "# Output layer with 3 neurons for predicting the PID gains: Kp, Ki, Kd\n",
        "pid_output = Dense(3, activation='linear')(pid_lstm)\n",
        "\n",
        "# Construct the model\n",
        "pid_model = Model(inputs=pid_input, outputs=pid_output)\n",
        "\n",
        "# Compile the model using Adam optimizer and mean squared error loss\n",
        "pid_model.compile(optimizer='adam', loss='mse')"
      ],
      "outputs": [],
      "metadata": {
        "id": "S6ZnvNxVUjNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshape Input and Train Model"
      ],
      "metadata": {
        "id": "14yAaQIZUm2E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# Reshape training data to match LSTM input format: (samples, timesteps, features)\n",
        "X_pid_train_reshaped = X_pid_train.reshape((X_pid_train.shape[0], X_pid_train.shape[1], 1))\n",
        "\n",
        "# Reshape test data similarly\n",
        "X_pid_test_reshaped = X_pid_test.reshape((X_pid_test.shape[0], X_pid_test.shape[1], 1))  # (samples, timesteps, features)\n",
        "\n",
        "# Train the LSTM model on the reshaped training data\n",
        "pid_model.fit(X_pid_train_reshaped, y_pid_train, epochs=50, batch_size=32, validation_data=(X_pid_test_reshaped, y_pid_test))\n",
        "\n",
        "# Save the trained model for later use\n",
        "pid_model.save(\"models/nn_pid_tuning_model.h5\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 7.1634e-06\n",
            "Epoch 2/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 5.6785e-06 - val_loss: 1.5987e-06\n",
            "Epoch 3/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 3.5327e-06 - val_loss: 9.2126e-07\n",
            "Epoch 4/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 2.4086e-06 - val_loss: 2.7863e-06\n",
            "Epoch 5/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.0639e-06 - val_loss: 1.2407e-06\n",
            "Epoch 6/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 1.5051e-06 - val_loss: 8.1904e-07\n",
            "Epoch 7/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 1.4886e-06 - val_loss: 2.7864e-06\n",
            "Epoch 8/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 1.3007e-06 - val_loss: 1.6097e-06\n",
            "Epoch 9/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 8.6046e-07 - val_loss: 2.1774e-06\n",
            "Epoch 10/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 5.8953e-07 - val_loss: 3.0782e-07\n",
            "Epoch 11/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 6.1504e-07 - val_loss: 4.2800e-07\n",
            "Epoch 12/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 5.2294e-07 - val_loss: 8.6408e-07\n",
            "Epoch 13/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 4.5948e-07 - val_loss: 2.5018e-07\n",
            "Epoch 14/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 6.3354e-07 - val_loss: 4.0175e-07\n",
            "Epoch 15/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 3.6791e-07 - val_loss: 5.8231e-07\n",
            "Epoch 16/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - loss: 5.5466e-07 - val_loss: 7.1685e-07\n",
            "Epoch 17/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 3.2964e-07 - val_loss: 1.3546e-07\n",
            "Epoch 18/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.8054e-07 - val_loss: 9.0831e-07\n",
            "Epoch 19/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 2.8342e-07 - val_loss: 1.6173e-07\n",
            "Epoch 20/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 2.8137e-07 - val_loss: 3.2268e-07\n",
            "Epoch 21/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 10ms/step - loss: 2.7160e-07 - val_loss: 1.6741e-07\n",
            "Epoch 22/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.1002e-07 - val_loss: 1.2322e-07\n",
            "Epoch 23/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 2.1938e-07 - val_loss: 2.7315e-07\n",
            "Epoch 24/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 1.8617e-07 - val_loss: 1.8041e-07\n",
            "Epoch 25/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 3.1935e-07 - val_loss: 6.6710e-08\n",
            "Epoch 26/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 2.1422e-07 - val_loss: 2.2039e-07\n",
            "Epoch 27/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.4981e-07 - val_loss: 2.0852e-07\n",
            "Epoch 28/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 2.1105e-07 - val_loss: 2.3018e-07\n",
            "Epoch 29/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 1.8225e-07 - val_loss: 1.1389e-07\n",
            "Epoch 30/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 2.1992e-07 - val_loss: 8.3796e-08\n",
            "Epoch 31/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 1.5133e-07 - val_loss: 7.3022e-07\n",
            "Epoch 32/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 1.7718e-07 - val_loss: 9.8922e-07\n",
            "Epoch 33/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 1.6714e-07 - val_loss: 2.8529e-07\n",
            "Epoch 34/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 1.2074e-07 - val_loss: 2.1195e-07\n",
            "Epoch 35/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 1.6423e-07 - val_loss: 8.0701e-08\n",
            "Epoch 36/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 1.3775e-07 - val_loss: 4.0720e-08\n",
            "Epoch 37/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 1.3383e-07 - val_loss: 5.4349e-08\n",
            "Epoch 38/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 1.2937e-07 - val_loss: 1.2304e-07\n",
            "Epoch 39/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 7.7320e-08 - val_loss: 5.6930e-07\n",
            "Epoch 40/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 2.5291e-07 - val_loss: 3.2506e-08\n",
            "Epoch 41/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - loss: 7.6113e-08 - val_loss: 4.7866e-08\n",
            "Epoch 42/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 1.2588e-07 - val_loss: 1.3392e-07\n",
            "Epoch 43/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 1.2220e-07 - val_loss: 3.1991e-07\n",
            "Epoch 44/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 2.0409e-07 - val_loss: 2.7427e-08\n",
            "Epoch 45/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 10ms/step - loss: 1.4228e-07 - val_loss: 2.2874e-08\n",
            "Epoch 46/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 1.5095e-07 - val_loss: 2.1645e-08\n",
            "Epoch 47/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 1.1918e-07 - val_loss: 4.3672e-08\n",
            "Epoch 48/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 1.0684e-07 - val_loss: 1.9392e-07\n",
            "Epoch 49/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 9.2044e-08 - val_loss: 7.0773e-08\n",
            "Epoch 50/50\n",
            "\u001b[1m2164/2164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 10ms/step - loss: 9.0300e-08 - val_loss: 1.9689e-07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Q1CeK0qUpWY",
        "outputId": "238460f5-9234-4f56-decb-61ec362eea8d"
      }
    }
  ]
}